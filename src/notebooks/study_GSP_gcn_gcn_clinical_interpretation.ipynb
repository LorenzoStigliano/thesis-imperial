{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1j/5s36wz6s0jlb1k64vsq1k2zh0000gn/T/ipykernel_21602/4118881939.py:18: MatplotlibDeprecationWarning: Support for setting an rcParam that expects a str value to a non-str value is deprecated since 3.5 and support will be removed two minor releases later.\n",
      "  plt.rcParams['text.latex.preamble']=[r\"\\usepackage{lmodern}\"]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/Users/lorenzostigliano/Documents/University/Imperial/Summer Term/thesis-imperial/src/')\n",
    "sys.path.append('/Users/lorenzostigliano/Documents/University/Imperial/Summer Term/thesis-imperial/src/utils')\n",
    "sys.path.append('/Users/lorenzostigliano/Documents/University/Imperial/Summer Term/thesis-imperial/src/models')\n",
    "\n",
    "from utils.analysis import *\n",
    "from utils.getters import * \n",
    "from utils.plotters import * \n",
    "from models_config.model_config_GSP import *\n",
    "from models_config.model_config_GSP_emb import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['text.latex.preamble']=[r\"\\usepackage{lmodern}\"]\n",
    "params = {\n",
    "    'text.usetex' : True,\n",
    "    'font.size' : 11,\n",
    "    'font.family' : 'lmodern'\n",
    "}\n",
    "plt.rcParams.update(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_CV_metric_student_model(dataset, model, analysis_type, training_type, view, run, student, dataset_split, model_args):\n",
    "\n",
    "    import sklearn.metrics as metrics\n",
    "\n",
    "    #get the mean metric for a student for a particular CV training_type \n",
    "    \n",
    "    student_acc, student_recall, student_precision, student_f1 = 0, 0, 0, 0\n",
    "    acc_mean, recall_mean, precision_mean, f1_mean = [], [], [], []\n",
    "    \n",
    "    if training_type == \"3Fold\":\n",
    "        cv_number = 3\n",
    "    if training_type == \"5Fold\":\n",
    "        cv_number = 5\n",
    "    if training_type == \"10Fold\":\n",
    "        cv_number = 10  \n",
    "    \n",
    "    for i in range(cv_number):\n",
    "        x = get_labels_and_preds(dataset=dataset, \n",
    "                                model=model,\n",
    "                                analysis_type=analysis_type, \n",
    "                                training_type=training_type,  \n",
    "                                cv_n=i, \n",
    "                                view=view, \n",
    "                                run=run, \n",
    "                                dataset_split=dataset_split, \n",
    "                                student=student, \n",
    "                                model_args=model_args)\n",
    "        result = {\n",
    "            'prec': metrics.precision_score(x['labels'],  x['preds']),\n",
    "            'recall': metrics.recall_score(x['labels'],  x['preds']),\n",
    "            'acc': metrics.accuracy_score(x['labels'],  x['preds']),\n",
    "            'F1': metrics.f1_score(x['labels'],  x['preds'])\n",
    "        }   \n",
    "        acc_mean.append(result['acc'])\n",
    "        recall_mean.append(result['recall'])\n",
    "        precision_mean.append(result['prec'])\n",
    "        f1_mean.append(result['F1'])\n",
    "    \n",
    "    student_acc = np.mean(acc_mean)\n",
    "    student_recall = np.mean(recall_mean)\n",
    "    student_precision = np.mean(precision_mean)\n",
    "    student_f1 = np.mean(f1_mean)\n",
    "\n",
    "    return student_acc, student_f1, student_recall, student_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_model_metric_all_folds(dataset, model, CV, runs, analysis_type, dataset_split, view, model_args):\n",
    "    #Get average student modele metrics across all runs and all cv for all models in ensemble \n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    runs = [i for i in range(10)]\n",
    "    CV=[\"3Fold\", \"5Fold\", \"10Fold\"]\n",
    "    model = \"gcn_student_ensamble_3\"\n",
    "    analysis_type=\"model_assessment\"\n",
    "    model_args= gcn_student_ensamble_args\n",
    "    dataset_split=\"val\"\n",
    "    view=2\n",
    "\n",
    "    get_student_model_metric_all_folds(dataset, model, CV, runs, analysis_type, dataset_split, view, model_args)\n",
    "    \"\"\"\n",
    "\n",
    "    all_student_metrics_mean = []\n",
    "    all_student_metrics_var = []\n",
    "\n",
    "    for student in range(model_args[\"n_students\"]):\n",
    "\n",
    "        model_metrics_runs = []\n",
    "        \n",
    "        for run in runs:\n",
    "                \n",
    "            model_metrics = []\n",
    "            \n",
    "            for training_type in CV:\n",
    "                \n",
    "                model_metrics.append(get_mean_CV_metric_student_model(\n",
    "                    dataset=dataset, \n",
    "                    model=model, \n",
    "                    analysis_type=analysis_type, \n",
    "                    training_type=training_type, \n",
    "                    view=view, \n",
    "                    run=run, \n",
    "                    student=student, \n",
    "                    dataset_split=dataset_split,\n",
    "                    model_args=model_args\n",
    "                )\n",
    "                )\n",
    "            \n",
    "            model_metrics = np.mean(model_metrics, axis=0)\n",
    "            model_metrics_runs.append(model_metrics)\n",
    "        all_student_metrics_var.append(np.var(model_metrics_runs, axis=0))\n",
    "        all_student_metrics_mean.append(np.mean(model_metrics_runs, axis=0))\n",
    "\n",
    "    return all_student_metrics_mean, all_student_metrics_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_student_ensamble(model, view, dataset, CV, runs, dataset_split, analysis_type, model_args):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    student_rep = []\n",
    "    student_var = []\n",
    "\n",
    "    # get the best reproducibility across all runs \n",
    "    for run in runs:\n",
    "\n",
    "        mean_all_runs = []\n",
    "\n",
    "        for student in range(model_args[\"n_students\"]):\n",
    "            view_rep, _ = view_reproducibility_analysis(\n",
    "                dataset=dataset, \n",
    "                models=[model], \n",
    "                CV=CV, \n",
    "                views=[view], \n",
    "                run=run, \n",
    "                students=[student], \n",
    "                model_args=[model_args]\n",
    "            )\n",
    "            mean_all_runs.append(view_rep[0][0])\n",
    "        #store the reproducibility score for all students for the run \n",
    "        student_rep.append(mean_all_runs)\n",
    "    \n",
    "    #get the mean and variance for the reproducibility scores for all the students\n",
    "    student_var = np.var(student_rep, axis=0)\n",
    "    student_rep = np.mean(student_rep, axis=0)\n",
    "\n",
    "    #get the metrics of all the student models\n",
    "    all_student_metrics_mean, _ = get_student_model_metric_all_folds(\n",
    "        dataset=dataset, \n",
    "        model=model, \n",
    "        CV=CV, \n",
    "        runs=runs, \n",
    "        analysis_type=analysis_type, \n",
    "        dataset_split=dataset_split, \n",
    "        view=view, \n",
    "        model_args=model_args\n",
    "    )\n",
    "    \n",
    "    #get the best model based soley on max reproducibility \n",
    "    best_rep_max = 0\n",
    "    metric = 0\n",
    "    student_max = -1\n",
    "    for i, rep in enumerate(student_rep):\n",
    "        if rep > metric:\n",
    "            best_rep_max = rep \n",
    "            metric = rep\n",
    "            student_max = i\n",
    "\n",
    "    #get the best model based on max reproducibility and accuracy\n",
    "    best_rep_acc = 0\n",
    "    metric = 0\n",
    "    student_acc_index = -1\n",
    "    for i, rep in enumerate(student_rep):\n",
    "        student_acc = all_student_metrics_mean[i][0]\n",
    "        if (rep+student_acc)/2 > metric:\n",
    "            metric = (rep+student_acc)/2 \n",
    "            best_rep_acc = rep\n",
    "            student_acc_index = i\n",
    "    \n",
    "    #get the best model based on max reproducibility and f1 score\n",
    "    best_rep_f1 = 0\n",
    "    metric = 0\n",
    "    student_f1_index = -1\n",
    "    for i, rep in enumerate(student_rep):\n",
    "        student_f1 = all_student_metrics_mean[i][1]\n",
    "        if (rep+student_f1)/2 > metric:\n",
    "            metric = (rep+student_f1)/2 \n",
    "            best_rep_f1 = rep\n",
    "            student_f1_index = i\n",
    "    \n",
    "    return [best_rep_max, student_var[student_max], student_max], [best_rep_acc, student_var[student_acc_index], student_acc_index], [best_rep_f1, student_var[student_f1_index], student_f1_index]\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the models and ensamble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_student_model_metric(dataset, model, CV, runs, analysis_type, dataset_split, view, model_args):\n",
    "    #Get average student modele metrics across all runs and all cv for all models in ensemble \n",
    "    #EACH FOLD INDIVIDUAL\n",
    "\n",
    "    student_data_mean = [] \n",
    "    student_data_var = [] \n",
    "    \n",
    "    for student in range(model_args[\"n_students\"]):\n",
    "\n",
    "        run_data = []   \n",
    "\n",
    "        for run in runs:\n",
    "\n",
    "            model_metrics = []\n",
    "            \n",
    "            for training_type in CV:\n",
    "\n",
    "                model_cv_metrics = get_mean_CV_metric_student_model(\n",
    "                    dataset=dataset, \n",
    "                    model=model, \n",
    "                    analysis_type=analysis_type, \n",
    "                    training_type=training_type, \n",
    "                    view=view, \n",
    "                    run=run, \n",
    "                    student=student, \n",
    "                    dataset_split=dataset_split,\n",
    "                    model_args=model_args\n",
    "                    )\n",
    "                model_metrics.append(model_cv_metrics)\n",
    "            \n",
    "            run_data.append(model_metrics)\n",
    "        \n",
    "        student_data_mean.append(np.mean(run_data, axis=0))   \n",
    "        student_data_var.append(np.std(run_data, axis=0))        \n",
    "\n",
    "    return student_data_mean, student_data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_metric(dataset, model, CV, runs, analysis_type, dataset_split, view, model_args):\n",
    "    #Get average metrics across all runs and all cv for any model \n",
    "    #EACH FOLD INDIVIDUAL\n",
    "\n",
    "    data_mean = [] \n",
    "    data_var = [] \n",
    "\n",
    "    run_data = []   \n",
    "\n",
    "\n",
    "    for run in runs:\n",
    "\n",
    "        model_metrics = []\n",
    "        \n",
    "        for training_type in CV:\n",
    "            \n",
    "            model_cv_metrics = get_mean_CV_metric_student_model(\n",
    "                dataset=dataset, \n",
    "                model=model, \n",
    "                analysis_type=analysis_type, \n",
    "                training_type=training_type, \n",
    "                view=view, \n",
    "                run=run, \n",
    "                student=-1, \n",
    "                dataset_split=dataset_split,\n",
    "                model_args=model_args\n",
    "                )\n",
    "            model_metrics.append(model_cv_metrics)\n",
    "        \n",
    "        run_data.append(model_metrics)\n",
    "        \n",
    "    data_mean.append(np.mean(run_data, axis=0))   \n",
    "    data_var.append(np.std(run_data, axis=0))        \n",
    "\n",
    "    return data_mean, data_var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPRODUCIBILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_reproducibility_analysis_student_specific(dataset, models, CV, views, run, students=[0], model_args=None):\n",
    "    \"\"\"\n",
    "    Reproducibility analysis for a single run for specific students in ensamble \n",
    "    student length = number of views, it is the specific student for each view\n",
    "    \"\"\"\n",
    "\n",
    "    view_data_mean = []\n",
    "    view_data_std = []\n",
    "\n",
    "    for i, view in enumerate(views):\n",
    "        \n",
    "        model_result_mean = []\n",
    "        model_result_std = []\n",
    "        ensamble_count = 0\n",
    "\n",
    "        for j, model in enumerate(models):\n",
    "\n",
    "            rep_score, std = view_specific_rep(dataset=dataset, view=view, model=model, run=run, CV=CV, student=students[ensamble_count][i], model_args=model_args[j])\n",
    "            model_result_mean.append(rep_score)\n",
    "            model_result_std.append(std)\n",
    "            \n",
    "            if \"ensamble\" in models:\n",
    "                ensamble_count += 1\n",
    "\n",
    "        view_data_mean.append(model_result_mean)\n",
    "        view_data_std.append(model_result_std)\n",
    "\n",
    "    view_data_std.append(list(np.std(view_data_mean, axis=0)))\n",
    "    view_data_std = np.array(view_data_std).T\n",
    "\n",
    "    view_data_mean.append(list(np.mean(view_data_mean, axis=0)))\n",
    "\n",
    "    view_data_mean = np.array(view_data_mean).T\n",
    "    \n",
    "    return view_data_mean, view_data_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar_chart_reproducibility_mulitple_runs_student_specific(dataset, views, models, CV, runs, students=0, model_args=None, save_fig=False):\n",
    "    \"\"\"\n",
    "    USAGE:\n",
    "    plot_bar_chart_reproducibility_mulitple_runs_student_specific(\n",
    "    dataset=\"gender_data\", \n",
    "    views=[0, 2, 4, 5], \n",
    "    models=[  \n",
    "        \"gcn\", \n",
    "        \"gcn_student\",\n",
    "        \"gcn_student_teacher\",\n",
    "        \"gcn_student_ensamble_3\", \n",
    "    ], \n",
    "    CV=[\"3Fold\", \"5Fold\", \"10Fold\"], \n",
    "    runs=[i for i in range(10)], \n",
    "    students=[2,0,2,0], \n",
    "    model_args= [\n",
    "        gcn_args,\n",
    "        gcn_student_args,\n",
    "        gcn_student_args,\n",
    "        gcn_student_ensamble_args,\n",
    "    ], \n",
    "    save_fig=False\n",
    "    )\n",
    "    \"\"\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "\n",
    "    barWidth = 1/(len(models)+1)\n",
    "\n",
    "    mean_all_runs = []\n",
    "    views=[0, 2, 4, 5]\n",
    "    runs=[i for i in range(10)]\n",
    "    for run in runs:\n",
    "        view_data_mean, _ = view_reproducibility_analysis_student_specific(dataset, models, CV, views, run, students=students, model_args=model_args)\n",
    "        mean_all_runs.append(view_data_mean)\n",
    "\n",
    "    mean_all_std = np.std(mean_all_runs, axis=0)\n",
    "    mean_all_runs = np.mean(mean_all_runs, axis=0)\n",
    "    \n",
    "    X = np.arange(len(views)+1)\n",
    "\n",
    "    sep = 0.00\n",
    "    for i, view_d in enumerate(mean_all_runs):\n",
    "        if models[i] == \"gcn\":\n",
    "            plt.bar(X + sep, view_d, yerr=mean_all_std[i], capsize=4, width = barWidth, edgecolor ='grey', label=models[i]+\"_teacher\", alpha=0.5)\n",
    "        elif models[i] == \"gcn_student_ensamble_3\":\n",
    "            plt.bar(X + sep, view_d, yerr=mean_all_std[i], capsize=4, width = barWidth, edgecolor ='grey', label=\"best_student_ensemble\", alpha=0.5)\n",
    "        else:\n",
    "            plt.bar(X + sep, view_d, yerr=mean_all_std[i], capsize=4, width = barWidth, edgecolor ='grey', label=models[i], alpha=0.5)\n",
    "        \n",
    "        sep += barWidth\n",
    "\n",
    "    max_y_lim = 1 if np.amax(mean_all_runs) + np.max(mean_all_std) > 1 else np.amax(mean_all_runs) + np.max(mean_all_std)\n",
    "    min_y_lim = 0 if np.amin(mean_all_runs) - np.max(mean_all_std) - 0.01 < 0 else np.amin(mean_all_runs) - np.max(mean_all_std) - 0.01\n",
    "    plt.ylim(min_y_lim, max_y_lim)\n",
    "\n",
    "    title = f\"Reproducibility Score for Dataset:{dataset} across {len(runs)} different seeds for best student\"\n",
    "\n",
    "    plt.ylabel(\"Reproducibility Score\")\n",
    "    x_ticks = [\"View {}\".format(i) for i in views]+ [\"Average\"]\n",
    "\n",
    "    plt.xticks([r + barWidth for r in range(len(mean_all_runs[0]))], x_ticks)\n",
    "    plt.title(title)\n",
    "    plt.grid(axis = 'y')\n",
    "    plt.legend()\n",
    "    if save_fig:\n",
    "        if not os.path.exists(SAVE_DIR_FIGS+\"ensemble_results/\"):\n",
    "            os.makedirs(SAVE_DIR_FIGS+\"ensemble_results/\")\n",
    "        \n",
    "        plt.savefig(SAVE_DIR_FIGS+\"ensemble_results/\"+title+\".png\", dpi=150,bbox_inches='tight')\n",
    "        plt.clf()\n",
    "    \n",
    "    else:\n",
    "        plt.show()\n",
    "        plt.clf()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_student_ensamble_detailed(model, view, CV, runs, dataset_split, analysis_type, model_args):\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    student_rep = []\n",
    "    student_var = []\n",
    "\n",
    "    # get the best reproducibility across all runs \n",
    "    for run in runs:\n",
    "\n",
    "        mean_all_runs = []\n",
    "\n",
    "        for student in range(model_args[\"n_students\"]):\n",
    "            view_rep, _ = view_reproducibility_analysis(\n",
    "                dataset=dataset, \n",
    "                models=[model], \n",
    "                CV=CV, \n",
    "                views=[view], \n",
    "                run=run, \n",
    "                students=[student], \n",
    "                model_args=[model_args]\n",
    "            )\n",
    "            mean_all_runs.append(view_rep[0][0])\n",
    "        #store the reproducibility score for all students for the run \n",
    "        student_rep.append(mean_all_runs)\n",
    "    \n",
    "    #get the mean and variance for the reproducibility scores for all the students\n",
    "    student_var = np.var(student_rep, axis=0)\n",
    "    student_rep = np.mean(student_rep, axis=0)\n",
    "\n",
    "    #get the metrics of all the student models\n",
    "    all_student_metrics_mean, all_student_metrics_var = get_student_model_metric_all_folds(\n",
    "        dataset=dataset, \n",
    "        model=model, \n",
    "        CV=CV, \n",
    "        runs=runs, \n",
    "        analysis_type=analysis_type, \n",
    "        dataset_split=dataset_split, \n",
    "        view=view, \n",
    "        model_args=model_args\n",
    "    )\n",
    "    \n",
    "    #get the best model based soley on max reproducibility \n",
    "    best_rep_max = 0\n",
    "    metric = 0\n",
    "    student_max = -1\n",
    "    for i, rep in enumerate(student_rep):\n",
    "        if rep > metric:\n",
    "            best_rep_max = rep \n",
    "            metric = rep\n",
    "            student_max = i\n",
    "\n",
    "    #get the best model based on max accuracy\n",
    "    best_max_acc = 0\n",
    "    metric = 0\n",
    "    student_max_acc_index = -1\n",
    "    for i, rep in enumerate(student_rep):\n",
    "        student_acc = all_student_metrics_mean[i][0]\n",
    "        if student_acc > metric:\n",
    "            metric = student_acc\n",
    "            best_max_acc = rep\n",
    "            student_max_acc_index = i\n",
    "\n",
    "    #get the best model based on max reproducibility and f1 score\n",
    "    best_max_f1 = 0\n",
    "    metric = 0\n",
    "    student_max_f1_index = -1\n",
    "    for i, rep in enumerate(student_rep):\n",
    "        student_f1 = all_student_metrics_mean[i][1]\n",
    "        if student_f1 > metric:\n",
    "            metric = student_f1\n",
    "            best_max_f1 = rep\n",
    "            student_max_f1_index = i\n",
    "\n",
    "    #get the best model based on max reproducibility and accuracy\n",
    "    best_rep_acc = 0\n",
    "    metric = 0\n",
    "    student_acc_index = -1\n",
    "    for i, rep in enumerate(student_rep):\n",
    "        student_acc = all_student_metrics_mean[i][0]\n",
    "        if (rep+student_acc)/2 > metric:\n",
    "            metric = (rep+student_acc)/2 \n",
    "            best_rep_acc = rep\n",
    "            student_acc_index = i\n",
    "    \n",
    "    #get the best model based on max reproducibility and f1 score\n",
    "    best_rep_f1 = 0\n",
    "    metric = 0\n",
    "    student_f1_index = -1\n",
    "    for i, rep in enumerate(student_rep):\n",
    "        student_f1 = all_student_metrics_mean[i][1]\n",
    "        if (rep+student_f1)/2 > metric:\n",
    "            metric = (rep+student_f1)/2 \n",
    "            best_rep_f1 = rep\n",
    "            student_f1_index = i\n",
    "    \n",
    "    return all_student_metrics_mean, all_student_metrics_var, [[best_rep_max, student_var[student_max], student_max], [best_max_acc, student_var[student_max_acc_index], student_max_acc_index], [best_max_f1, student_var[student_max_f1_index], student_max_f1_index], [best_rep_acc, student_var[student_acc_index], student_acc_index], [best_rep_f1, student_var[student_f1_index], student_f1_index]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(dataset, view, model, run, student, model_args=None):\n",
    "    weights = []\n",
    "    for cv_n in range(3):\n",
    "        weights.append(get_weight(dataset, view, model, \"3Fold\", 0, cv_n, run, student, model_args=model_args))\n",
    "    for cv_n in range(5):\n",
    "        weights.append(get_weight(dataset, view, model, \"5Fold\", 0, cv_n, run, student, model_args=model_args))\n",
    "    for cv_n in range(10):\n",
    "        weights.append(get_weight(dataset, view, model, \"10Fold\", 0, cv_n, run, student, model_args=model_args))\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_split=\"val\"\n",
    "dataset = \"gender_data\"\n",
    "\n",
    "dis = []\n",
    "\n",
    "for run in range(10):\n",
    "\n",
    "    all_views_dis = []\n",
    "    all_views_no_dis = []\n",
    "\n",
    "    for view in [0,2,4,5]:\n",
    "\n",
    "        dis_view = []\n",
    "        \n",
    "        for student in [0,1,2,3]:\n",
    "            dis_view.append(extract_weights(dataset=dataset, \n",
    "                            view=view, \n",
    "                            model=gcn_student_lsp_ensamble_4_args[\"model_name\"], \n",
    "                            run=run, \n",
    "                            student=student, \n",
    "                            model_args=gcn_student_lsp_ensamble_4_args))\n",
    "        \n",
    "        all_views_dis.append(dis_view)\n",
    "\n",
    "    dis.append(all_views_dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2,1,2,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [np.abs(np.mean(dis[0][0][2],axis=0)), np.abs(np.mean(dis[0][1][1],axis=0)), np.abs(np.mean(dis[0][2][2],axis=0)), np.abs(np.mean(dis[0][3][1],axis=0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.mean(x, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13072726, 0.13951984, 0.11718448, 0.05603635, 0.15121764,\n",
       "       0.12207612, 0.08546476, 0.11959788, 0.10563517, 0.07958572,\n",
       "       0.09139051, 0.07531274, 0.15088941, 0.12047654, 0.06034484,\n",
       "       0.07263748, 0.05835674, 0.04134506, 0.08323871, 0.04535076,\n",
       "       0.05926897, 0.1346688 , 0.08365707, 0.16205174, 0.17513928,\n",
       "       0.06115662, 0.09999743, 0.12043419, 0.09372913, 0.08389772,\n",
       "       0.05551011, 0.07964937, 0.050348  , 0.08112493, 0.02001393],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24, 23,  4, 12,  1, 21,  0,  5, 13, 27,  7,  2,  8, 26, 28, 10,  6,\n",
       "       29, 22, 18, 33, 31,  9, 11, 15, 25, 14, 20, 16,  3, 30, 32, 19, 17,\n",
       "       34])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "        \"Bank of the Superior Temporal Sulcus\",#1\n",
    "        \"Caudal Anterior-cingulate Cortex\",#2\n",
    "        \"Caudal Middle Frontal Gyrus\",#3\n",
    "        \"Unmeasured Corpus Callosum\",#4\n",
    "        \"Cunesus Cortex\",#5\n",
    "        \"Entorhinal Cortex\",#6\n",
    "        \"Fusiform Gyrus\",#7\n",
    "        \"Inferior Parietal Cortex\",#8\n",
    "        \"Inferior Temporal Gyrus\",#9\n",
    "        \"Isthmus-cingulate Cortex\",#10\n",
    "        \"Lateral occipital cortex\",#11\n",
    "        \"Lateral orbital frontal cortex\",#12\n",
    "        \"Lingual gyrus\",#13\n",
    "        \"Medial orbital frontal cortex\",#14\n",
    "        \"Middle temporal gyrus\",#15\n",
    "        \"Parahippocampal gyrus\",#16\n",
    "        \"Paracentral lobule\",#17\n",
    "        \"Pars opercularis\",#18\n",
    "        \"Pars orbitalis\",#19\n",
    "        \"Pars triangularis\",#20\n",
    "        \"Pericalcarine cortex\",#21\n",
    "        \"Postcentral gyrus\",#22\n",
    "        \"Posterior-cingulate cortex\",#23\n",
    "        \"Precentral gyrus\",#24\n",
    "        \"Precuneus cortex\",#25\n",
    "        \"Rostral anterior cingulate cortex\",#26\n",
    "        \"Rostral middle frontal gyrus\",#£7\n",
    "        \"Superior frontal gyrus\",#28\n",
    "        \"Superior parietal cortex\",#29\n",
    "        \"Superior temporal gyrus\",#30\n",
    "        \"Supramarginal gyrus\",#31\n",
    "        \"Frontal pole\",#32\n",
    "        \"Temporal pole\",#33\n",
    "        \"Transverse temporal cortex\",#34\n",
    "        \"Insula cortex\"#35\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Precuneus cortex',\n",
       " 'Precentral gyrus',\n",
       " 'Cunesus Cortex',\n",
       " 'Lingual gyrus',\n",
       " 'Caudal Anterior-cingulate Cortex')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[24],  labels[23],  labels[4],  labels[12],  labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cingulate cortex, medial and lateral frontal cortex, temporoparietal regions, insula, and precuneus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO DO FOR ALL OF THE MODELS AND SEE IF THEY FIND THE SAME REGIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_config.model_config_GSP import *\n",
    "\n",
    "dataset_split=\"val\"\n",
    "dataset = \"gender_data\"\n",
    "\n",
    "dis = []\n",
    "\n",
    "for run in range(10):\n",
    "\n",
    "    all_views_dis = []\n",
    "    all_views_no_dis = []\n",
    "\n",
    "    for view in [0,2,4,5]:\n",
    "\n",
    "        dis_view = []\n",
    "        \n",
    "        for student in [0,1,2,3]:\n",
    "            dis_view.append(extract_weights(dataset=dataset, \n",
    "                            view=view, \n",
    "                            model=gcn_gat_student_lsp_ensamble_4_args[\"model_name\"], \n",
    "                            run=run, \n",
    "                            student=student, \n",
    "                            model_args=gcn_gat_student_lsp_ensamble_4_args))\n",
    "        \n",
    "        all_views_dis.append(dis_view)\n",
    "\n",
    "    dis.append(all_views_dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 10, 14, 24, 33, 25, 18, 29, 21,  9, 27, 32,  7,  1,  4, 12, 23,\n",
       "       16, 17, 30,  6, 11, 20,  3, 26, 13, 34, 22, 19,  8, 31, 28,  2,  0,\n",
       "       15])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [np.abs(np.mean(dis[0][0][1],axis=0)), np.abs(np.mean(dis[0][1][3],axis=0)), np.abs(np.mean(dis[0][2][1],axis=0)), np.abs(np.mean(dis[0][3][3],axis=0))]\n",
    "x = np.mean(x, axis=0)\n",
    "np.argsort(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5, 7, 10, 12, 21, 23, 24, 27, 29]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [5, 10, 14, 24, 33, 25, 18, 29, 21,  9, 27, 32,  7,  1,  4, 12, 23, 16]\n",
    "b = [24, 23,  4, 12,  1, 21,  0,  5, 13, 27,  7,  2,  8, 26, 28, 10,  6, 29]\n",
    "list(set(a) & set(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_config.model_config_GSP import *\n",
    "\n",
    "dataset_split=\"val\"\n",
    "dataset = \"gender_data\"\n",
    "\n",
    "dis = []\n",
    "\n",
    "for run in range(10):\n",
    "\n",
    "    all_views_dis = []\n",
    "    all_views_no_dis = []\n",
    "\n",
    "    for view in [0,2,4,5]:\n",
    "\n",
    "        dis_view = []\n",
    "        \n",
    "        for student in [0,1]:\n",
    "            dis_view.append(extract_weights(dataset=dataset, \n",
    "                            view=view, \n",
    "                            model=gat_gat_student_lsp_ensamble_2_args[\"model_name\"], \n",
    "                            run=run, \n",
    "                            student=student, \n",
    "                            model_args=gat_gat_student_lsp_ensamble_2_args))\n",
    "        \n",
    "        all_views_dis.append(dis_view)\n",
    "\n",
    "    dis.append(all_views_dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, 10, 14, 21, 23, 27,  7, 22, 30,  9, 25,  5, 12,  6, 11, 24, 33,\n",
       "       20, 29, 28,  3, 26, 34,  1, 18,  8, 32,  2, 16, 15, 31, 13, 17, 19,\n",
       "        0])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [np.abs(np.mean(dis[0][0][1],axis=0)), np.abs(np.mean(dis[0][1][1],axis=0)), np.abs(np.mean(dis[0][2][1],axis=0)), np.abs(np.mean(dis[0][3][0],axis=0))]\n",
    "x = np.mean(x, axis=0)\n",
    "np.argsort(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 7, 10, 12, 21, 23, 24, 27]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [4, 10, 14, 21, 23, 27,  7, 22, 30,  9, 25,  5, 12,  6, 11, 24, 33, 20]\n",
    "d = [1, 4, 5, 7, 10, 12, 21, 23, 24, 27, 29]\n",
    "list(set(c) & set(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_config.model_config_GSP import *\n",
    "\n",
    "dataset_split=\"val\"\n",
    "dataset = \"gender_data\"\n",
    "\n",
    "dis = []\n",
    "\n",
    "for run in range(10):\n",
    "\n",
    "    all_views_dis = []\n",
    "    all_views_no_dis = []\n",
    "\n",
    "    for view in [0,2,4,5]:\n",
    "\n",
    "        dis_view = []\n",
    "        \n",
    "        for student in [0,1,2,3]:\n",
    "            dis_view.append(extract_weights(dataset=dataset, \n",
    "                            view=view, \n",
    "                            model=gat_student_lsp_ensamble_4_args[\"model_name\"], \n",
    "                            run=run, \n",
    "                            student=student, \n",
    "                            model_args=gat_student_lsp_ensamble_4_args))\n",
    "        \n",
    "        all_views_dis.append(dis_view)\n",
    "\n",
    "    dis.append(all_views_dis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23,  7, 12, 29, 27, 18, 26, 16, 13,  1, 22,  9, 28, 11, 20,  6, 33,\n",
       "       14,  3, 24, 15, 34, 25, 32,  8, 19,  2, 10,  5, 21, 31, 30,  0, 17,\n",
       "        4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[3,1,2,1]\n",
    "x = [np.abs(np.mean(dis[0][0][3],axis=0)), np.abs(np.mean(dis[0][1][1],axis=0)), np.abs(np.mean(dis[0][2][1],axis=0)), np.abs(np.mean(dis[0][3][1],axis=0))]\n",
    "x = np.mean(x, axis=0)\n",
    "np.argsort(-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27, 12, 23, 7]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [23,  7, 12, 29, 27, 18, 26, 16, 13,  1, 22,  9, 28, 11, 20,  6, 33, 14]\n",
    "d = [4, 5, 7, 10, 12, 21, 23, 24, 27]\n",
    "list(set(c) & set(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Superior frontal gyrus',\n",
       " 'Lingual gyrus',\n",
       " 'Precentral gyrus',\n",
       " 'Inferior Parietal Cortex')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[27],  labels[12],  labels[23],  labels[7]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-test",
   "language": "python",
   "name": "env-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
