{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from analysis import *\n",
    "from getters import * \n",
    "from plotters import * \n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gcn_args = {\n",
    "    \"num_epochs\":50, \n",
    "    \"lr\": 0.0001,\n",
    "    \"weight_decay\":5e-4, \n",
    "    \"hidden_dim\":64,\n",
    "    \"dropout\":0,\n",
    "    \"threshold\":\"median\", # Threshold the graph adjacency matrix. Possible values: no_threshold, median, mean\n",
    "    \"model_name\":\"gcn\",\n",
    "    \"layers\":2,\n",
    "    \"evaluation_method\": \"model_assessment\" # model selection or model assessment\n",
    "}\n",
    "\n",
    "gcn_3_args = {\n",
    "    \"num_epochs\":50, \n",
    "    \"lr\": 0.0001,\n",
    "    \"weight_decay\":5e-4, \n",
    "    \"hidden_dim\":64,\n",
    "    \"dropout\":0,\n",
    "    \"threshold\":\"median\", # Threshold the graph adjacency matrix. Possible values: no_threshold, median, mean\n",
    "    \"model_name\":\"gcn\",\n",
    "    \"layers\":3,\n",
    "    \"evaluation_method\": \"model_assessment\" # model selection or model assessment\n",
    "}\n",
    "\n",
    "gcn_student_args = {\n",
    "    \"num_epochs\":50, \n",
    "    \"lr\": 0.0001, \n",
    "    \"weight_decay\":5e-4, \n",
    "    \"hidden_dim\":64,\n",
    "    \"dropout\":0,\n",
    "    \"threshold\":\"median\", # Threshold the graph adjacency matrix. Possible values: no_threshold, median, mean\n",
    "    \"model_name\":\"gcn_student\",\n",
    "    \"evaluation_method\": \"model_assessment\", # model selection or model assessment\n",
    "    \"alpha_ce\": 1, \n",
    "    \"T\": 3, \n",
    "    \"alpha_soft_ce\": 2,\n",
    "    \"alpha_weight\": 0\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_dir = '/Users/lorenzostigliano/Documents/University/Imperial/Summer Term/thesis-imperial/model_data/model_assessment/gcn_student/models/gcn_student_MainModel_3Fold_gender_data_gcn_student_run_0_fixed_init_CV_0_view_0.pt'\n",
    "model_2_dir = '/Users/lorenzostigliano/Documents/University/Imperial/Summer Term/thesis-imperial/model_data/model_assessment/gcn/models/gcn_MainModel_3Fold_gender_data_gcn_run_0_fixed_init_CV_0_view_0.pt'\n",
    "\n",
    "model_layer_1 = torch.load(model_1_dir)\n",
    "model_layer_2 = torch.load(model_2_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 2470)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model_layer_1), count_parameters(model_layer_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def lsp(node_embeddings, adjacency_matrix, sigma=1.0):\n",
    "\n",
    "    # Compute the squared Euclidean distance matrix between node embeddings\n",
    "    squared_distances = torch.cdist(node_embeddings, node_embeddings, p=2).pow(2)\n",
    "    \n",
    "    # Apply the RBF kernel to the squared distance matrix\n",
    "    similarity_matrix = torch.exp(-squared_distances / (2 * sigma**2))\n",
    "    \n",
    "    # Cast the adjacency matrix to Float\n",
    "    adjacency_matrix = adjacency_matrix.float()\n",
    "    \n",
    "    # Compute the sum of similarities for each node's neighbors\n",
    "    sum_similarities = torch.sum(adjacency_matrix * similarity_matrix, dim=1)\n",
    "    \n",
    "    # Compute the local structure by dividing each node's similarity by the sum\n",
    "    local_structure = similarity_matrix / sum_similarities.unsqueeze(1)\n",
    "    \n",
    "    return local_structure\n",
    "\n",
    "# Example usage\n",
    "node_embeddings = torch.tensor([[1.0,1.0], \n",
    "                                [2.0,2.0], \n",
    "                                [3.0,3.0]])\n",
    "\n",
    "adjacency_matrix = torch.tensor([[1, 0, 1], \n",
    "                                 [0, 0, 1], \n",
    "                                 [1, 1, 1]])\n",
    "\n",
    "local_structure = lsp(node_embeddings, adjacency_matrix, sigma=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0.9820, 0.0180]), tensor([1.]), tensor([0.0132, 0.2654, 0.7214])]\n"
     ]
    }
   ],
   "source": [
    "def extract_ls_vectors(local_structure, adjacency_matrix):\n",
    "    # Create a sparse mask tensor from the adjacency matrix\n",
    "    mask = adjacency_matrix.to_sparse().to_dense()\n",
    "    \n",
    "    # Multiply the mask tensor element-wise with the local structure tensor\n",
    "    ls_vectors = mask * local_structure\n",
    "\n",
    "    non_zero_rows = []\n",
    "    for row in ls_vectors:\n",
    "        # Select non-zero elements in the row\n",
    "        non_zero_elements = row[row != 0.0]\n",
    "        non_zero_rows.append(non_zero_elements)\n",
    "    \n",
    "    return non_zero_rows\n",
    "\n",
    "# Example usage\n",
    "ls_vectors = extract_ls_vectors(local_structure, adjacency_matrix)\n",
    "\n",
    "print(ls_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def inference_time(model, model_args):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    G_list = load_data(\"gender_data\", 0, NormalizeInputGraphs=False)\n",
    "\n",
    "    folds = stratify_splits(G_list, 3)\n",
    "        \n",
    "    [random.shuffle(folds[i]) for i in range(len(folds))]\n",
    "    train_set, validation_set, test_set = datasets_splits(folds, model_args, 0)\n",
    "    train_dataset, val_dataset, threshold_value = model_assessment_split(train_set, validation_set, test_set, gcn_student_args)\n",
    "\n",
    "    for batch_idx, data in enumerate(train_dataset):\n",
    "\n",
    "        adj = Variable(data['adj'].float(), requires_grad=False).to(device)\n",
    "        adj = torch.squeeze(adj)\n",
    "\n",
    "        features = np.identity(adj.shape[0])\n",
    "        features = Variable(torch.from_numpy(features).float(), requires_grad=False).to(\"cpu\")\n",
    "        if gcn_student_args[\"threshold\"] in [\"median\", \"mean\"]:\n",
    "            adj = torch.where(adj > threshold_value, torch.tensor([1.0]).to(\"cpu\"), torch.tensor([0.0]).to(\"cpu\"))\n",
    "\n",
    "        begin_time = time.time()\n",
    "\n",
    "        _, node_embeddings = model(features, adj)\n",
    "        extract_ls_vectors(lsp(node_embeddings, adj),adj)\n",
    "        print(len(extract_ls_vectors(lsp(node_embeddings, adj),adj)))\n",
    "        \n",
    "        student_ls_vectors_reshaped = torch.cat(student_non_zero_rows, dim=0).view(-1, student_non_zero_rows[0].size(-1))\n",
    "        teacher_ls_vectors_reshaped = torch.cat(teacher_non_zero_rows, dim=0).view(-1, teacher_non_zero_rows[0].size(-1))\n",
    "\n",
    "        return time.time() - begin_time\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training graphs:  466 ; Num test graphs:  232\n",
      "35\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.006639003753662109"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_time(model_layer_1, gcn_student_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-test",
   "language": "python",
   "name": "env-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
