{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from analysis import *\n",
    "from getters import * \n",
    "from plotters import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>View 0</th>\n",
       "      <th>View 2</th>\n",
       "      <th>View 4</th>\n",
       "      <th>View 5</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Teacher</th>\n",
       "      <td>0.535972</td>\n",
       "      <td>0.508611</td>\n",
       "      <td>0.536944</td>\n",
       "      <td>0.503194</td>\n",
       "      <td>0.521181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student</th>\n",
       "      <td>0.481667</td>\n",
       "      <td>0.544167</td>\n",
       "      <td>0.482083</td>\n",
       "      <td>0.538472</td>\n",
       "      <td>0.511597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student + Teacher</th>\n",
       "      <td>0.484583</td>\n",
       "      <td>0.558889</td>\n",
       "      <td>0.497639</td>\n",
       "      <td>0.531528</td>\n",
       "      <td>0.518160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Student + Teacher + Weight Loss</th>\n",
       "      <td>0.493056</td>\n",
       "      <td>0.529444</td>\n",
       "      <td>0.486528</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.496701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   View 0    View 2    View 4    View 5  \\\n",
       "Teacher                          0.535972  0.508611  0.536944  0.503194   \n",
       "Student                          0.481667  0.544167  0.482083  0.538472   \n",
       "Student + Teacher                0.484583  0.558889  0.497639  0.531528   \n",
       "Student + Teacher + Weight Loss  0.493056  0.529444  0.486528  0.477778   \n",
       "\n",
       "                                  Average  \n",
       "Teacher                          0.521181  \n",
       "Student                          0.511597  \n",
       "Student + Teacher                0.518160  \n",
       "Student + Teacher + Weight Loss  0.496701  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(mean_all_runs, columns=[\"View {}\".format(i) for i in views]+ [\"Average\"], index=[\"Teacher\", \"Student\", \"Student + Teacher\", \"Student + Teacher + Weight Loss\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis for each view we create the metric tables across the different models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_and_view_analysis(models, CV, analysis_type, view, run, dataset_split, dataset, metric):\n",
    "    \"\"\"\n",
    "    Mean of metric for a specific CV -> 3, 5 or 10\n",
    "    \"\"\"\n",
    "\n",
    "    all_data_mean = []\n",
    "    all_data_std = []\n",
    "    \n",
    "    for model in models:\n",
    "        \n",
    "        model_results_mean = []\n",
    "        model_results_std = []\n",
    "       \n",
    "        for training_type in CV:\n",
    "            metrics = extract_metrics(dataset=dataset, model=model, analysis_type=analysis_type, training_type=training_type, view=view, run=run, dataset_split=dataset_split, metric=metric)\n",
    "            mean = np.mean([metric[-1] for metric in metrics])\n",
    "            std = np.std([metric[-1] for metric in metrics])\n",
    "            model_results_mean.append(mean)\n",
    "            model_results_std.append(std)\n",
    "        \n",
    "        all_data_mean.append(model_results_mean)\n",
    "        all_data_std.append(model_results_std)\n",
    "    \n",
    "    return all_data_mean, all_data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_metric_analysis(models, CV, view, run, metric, dataset):\n",
    "\n",
    "    view_data_mean = []\n",
    "    view_data_std = []\n",
    "\n",
    "    mean, std = metric_and_view_analysis(models=models, \n",
    "                                    CV=CV, \n",
    "                                    analysis_type=\"model_assessment\", \n",
    "                                    view=view, \n",
    "                                    run=run, \n",
    "                                    dataset= dataset,\n",
    "                                    dataset_split=\"val\", \n",
    "                                    metric=metric)\n",
    "    view_data_mean.append(mean)\n",
    "    view_data_std.append(std)\n",
    "    \n",
    "    return view_data_mean, view_data_std "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.60686954, 0.60995643, 0.60961415, 0.60881337],\n",
       "        [0.57161681, 0.59281791, 0.59920572, 0.58788015],\n",
       "        [0.57749533, 0.59901104, 0.60518728, 0.59389788],\n",
       "        [0.54751081, 0.55423042, 0.5613834 , 0.55437487]]),\n",
       " array([[0.01529327, 0.01794911, 0.01028801, 0.00119649],\n",
       "        [0.0249576 , 0.0170908 , 0.01732294, 0.01021208],\n",
       "        [0.02112357, 0.01607898, 0.0171574 , 0.01027909],\n",
       "        [0.01541351, 0.01567641, 0.01292345, 0.0049055 ]]))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_all_runs = []\n",
    "for run in [i for i in range(10)]:\n",
    "    view_data_mean, view_data_std = view_metric_analysis(models=models, CV=CV, view=0, run=run, metric=\"acc\", dataset=dataset)\n",
    "    mean_all_runs.append(view_data_mean)\n",
    "\n",
    "mean_all_std = np.std(mean_all_runs, axis=0).squeeze()\n",
    "mean_all_runs = np.mean(mean_all_runs, axis=0).squeeze()\n",
    "\n",
    "#GET MEAN AND STD ACROSS MEAN OF RUNS\n",
    "mean_all_runs = np.c_[ mean_all_runs, np.mean(mean_all_runs, axis=1)]     \n",
    "mean_all_std = np.c_[ mean_all_std, np.std(mean_all_runs, axis=1)]  \n",
    "\n",
    "mean_all_runs, mean_all_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________\n",
      "View: 0 Metric: acc\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.602±0.017  0.593±0.038  0.599±0.057\n",
      "Student                          0.571±0.049  0.603±0.042  0.575±0.042\n",
      "Student + Teacher                0.582±0.042  0.602±0.042  0.592±0.042\n",
      "Student + Teacher + Weight Loss   0.532±0.01    0.54±0.04   0.56±0.058\n",
      "____________________________________________________\n",
      "View: 0 Metric: f1\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.437±0.046   0.487±0.04  0.519±0.068\n",
      "Student                          0.381±0.087   0.467±0.08  0.423±0.095\n",
      "Student + Teacher                  0.35±0.14  0.492±0.071   0.436±0.13\n",
      "Student + Teacher + Weight Loss   0.17±0.094  0.339±0.077  0.311±0.167\n",
      "____________________________________________________\n",
      "View: 0 Metric: recall\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.355±0.055   0.44±0.052  0.497±0.089\n",
      "Student                          0.303±0.078   0.401±0.09  0.369±0.123\n",
      "Student + Teacher                0.273±0.124  0.444±0.083  0.384±0.145\n",
      "Student + Teacher + Weight Loss  0.117±0.077  0.274±0.076  0.255±0.171\n",
      "____________________________________________________\n",
      "View: 0 Metric: precision\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.576±0.032  0.553±0.057  0.554±0.077\n",
      "Student                          0.516±0.096  0.564±0.057  0.526±0.075\n",
      "Student + Teacher                0.515±0.116  0.558±0.057   0.54±0.108\n",
      "Student + Teacher + Weight Loss  0.364±0.062  0.462±0.065  0.457±0.141\n",
      "____________________________________________________\n",
      "View: 2 Metric: acc\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.668±0.015  0.645±0.031  0.666±0.075\n",
      "Student                          0.619±0.007   0.62±0.026  0.657±0.069\n",
      "Student + Teacher                0.627±0.008    0.62±0.03  0.645±0.071\n",
      "Student + Teacher + Weight Loss     0.6±0.02  0.607±0.021  0.617±0.075\n",
      "____________________________________________________\n",
      "View: 2 Metric: f1\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.612±0.038  0.612±0.058  0.658±0.077\n",
      "Student                          0.502±0.009  0.526±0.028  0.549±0.102\n",
      "Student + Teacher                0.517±0.014  0.548±0.041    0.541±0.1\n",
      "Student + Teacher + Weight Loss  0.403±0.096  0.493±0.045  0.486±0.137\n",
      "____________________________________________________\n",
      "View: 2 Metric: recall\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.602±0.069  0.648±0.105  0.736±0.106\n",
      "Student                          0.436±0.011  0.479±0.038  0.486±0.121\n",
      "Student + Teacher                0.453±0.015  0.524±0.056  0.486±0.122\n",
      "Student + Teacher + Weight Loss   0.32±0.104  0.436±0.056   0.431±0.14\n",
      "____________________________________________________\n",
      "View: 2 Metric: precision\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.627±0.005  0.586±0.028   0.601±0.08\n",
      "Student                           0.59±0.012  0.587±0.042   0.653±0.11\n",
      "Student + Teacher                0.602±0.012  0.575±0.037  0.637±0.112\n",
      "Student + Teacher + Weight Loss  0.582±0.029   0.568±0.03   0.584±0.11\n",
      "____________________________________________________\n",
      "View: 4 Metric: acc\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                            0.66±0.04  0.654±0.037  0.674±0.044\n",
      "Student                          0.625±0.025   0.63±0.043   0.64±0.056\n",
      "Student + Teacher                0.641±0.028  0.639±0.045   0.646±0.05\n",
      "Student + Teacher + Weight Loss  0.632±0.026  0.616±0.042   0.575±0.07\n",
      "____________________________________________________\n",
      "View: 4 Metric: f1\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.561±0.055   0.607±0.05  0.624±0.055\n",
      "Student                          0.479±0.085  0.498±0.104  0.522±0.112\n",
      "Student + Teacher                0.507±0.093  0.518±0.112  0.539±0.085\n",
      "Student + Teacher + Weight Loss   0.45±0.038  0.416±0.144  0.378±0.121\n",
      "____________________________________________________\n",
      "View: 4 Metric: recall\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.495±0.056  0.612±0.081  0.616±0.066\n",
      "Student                          0.404±0.103   0.43±0.115   0.463±0.13\n",
      "Student + Teacher                0.437±0.117  0.459±0.126   0.48±0.102\n",
      "Student + Teacher + Weight Loss  0.342±0.029  0.336±0.146   0.306±0.12\n",
      "____________________________________________________\n",
      "View: 4 Metric: precision\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.649±0.057  0.608±0.042   0.634±0.06\n",
      "Student                          0.607±0.022  0.607±0.076  0.625±0.087\n",
      "Student + Teacher                0.629±0.019  0.611±0.074   0.63±0.086\n",
      "Student + Teacher + Weight Loss  0.657±0.056  0.598±0.063  0.529±0.104\n",
      "____________________________________________________\n",
      "View: 5 Metric: acc\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                           0.67±0.011  0.652±0.051  0.667±0.077\n",
      "Student                          0.632±0.043   0.64±0.036   0.65±0.046\n",
      "Student + Teacher                0.639±0.038  0.648±0.042   0.66±0.051\n",
      "Student + Teacher + Weight Loss   0.603±0.01  0.648±0.043  0.624±0.055\n",
      "____________________________________________________\n",
      "View: 5 Metric: f1\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.584±0.039   0.625±0.04  0.634±0.085\n",
      "Student                          0.533±0.065  0.541±0.065  0.574±0.052\n",
      "Student + Teacher                 0.543±0.07  0.569±0.065  0.591±0.056\n",
      "Student + Teacher + Weight Loss  0.445±0.064  0.542±0.055   0.44±0.137\n",
      "____________________________________________________\n",
      "View: 5 Metric: recall\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                           0.531±0.07  0.655±0.032  0.661±0.116\n",
      "Student                           0.482±0.07  0.489±0.085  0.537±0.048\n",
      "Student + Teacher                0.495±0.087  0.534±0.082  0.557±0.047\n",
      "Student + Teacher + Weight Loss  0.371±0.087  0.476±0.069  0.357±0.143\n",
      "____________________________________________________\n",
      "View: 5 Metric: precision\n",
      "                                       3Fold        5Fold       10Fold\n",
      "Teacher                          0.656±0.013  0.599±0.057   0.62±0.096\n",
      "Student                            0.6±0.058  0.612±0.042  0.621±0.077\n",
      "Student + Teacher                0.608±0.049   0.612±0.05  0.633±0.085\n",
      "Student + Teacher + Weight Loss  0.576±0.004  0.641±0.082   0.625±0.13\n"
     ]
    }
   ],
   "source": [
    "views=[0, 2, 4, 5]\n",
    "models=[\"gcn\", \"gcn_student\", \"gcn_student_teacher\", \"gcn_student_teacher_weight\"]\n",
    "CV=[\"3Fold\", \"5Fold\", \"10Fold\"]\n",
    "run=1\n",
    "dataset = \"gender_data\"\n",
    "dataset_split = [\"val\", \"train\", \"test\"]\n",
    "metrics = [\"acc\", \"f1\", \"recall\", \"precision\"]\n",
    "\n",
    "for view in views:\n",
    "    for metric in metrics:\n",
    "        print(\"____________________________________________________\")\n",
    "        print(f\"View: {view} Metric: {metric}\")\n",
    "        mean, std = metric_and_view_analysis(models=models, \n",
    "                                            CV=CV, \n",
    "                                            analysis_type=\"model_assessment\", \n",
    "                                            view=view, \n",
    "                                            run=run, \n",
    "                                            dataset= dataset,\n",
    "                                            dataset_split=\"val\", \n",
    "                                            metric=metric)\n",
    "        mean = pd.DataFrame(mean, columns=CV, index=[\"Teacher\", \"Student\", \"Student + Teacher\", \"Student + Teacher + Weight Loss\"]).round(3)\n",
    "        std = pd.DataFrame(std, columns=CV, index=[\"Teacher\", \"Student\", \"Student + Teacher\", \"Student + Teacher + Weight Loss\"]).round(3)\n",
    "        print(mean.astype(str) + u\"\\u00B1\" + std.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'w': Parameter containing:\n",
      "tensor([[-0.1489,  0.0162, -0.1194, -0.0202, -0.1403, -0.1091, -0.0803,  0.1808,\n",
      "         -0.0033,  0.0470,  0.0215,  0.0081, -0.0315, -0.1461, -0.0013,  0.1489,\n",
      "         -0.0930,  0.1272, -0.0292,  0.0739, -0.0244, -0.0515, -0.1271, -0.0550,\n",
      "          0.0735,  0.0621,  0.0910,  0.1108,  0.0337,  0.1760, -0.0632,  0.0315,\n",
      "          0.0906,  0.1465, -0.0711]], requires_grad=True)}\n",
      "{'w': Parameter containing:\n",
      "tensor([[-0.0586, -0.0967, -0.0213, -0.0423,  0.0074,  0.1082,  0.1008, -0.0700,\n",
      "          0.1325,  0.1787,  0.0710, -0.1253,  0.1156, -0.0651,  0.0839, -0.0171,\n",
      "          0.1840,  0.0957, -0.0952, -0.1685,  0.0776, -0.1542,  0.2262,  0.2231,\n",
      "          0.0125,  0.1908, -0.1573,  0.1821,  0.1211, -0.1819, -0.0794, -0.0089,\n",
      "          0.0631, -0.0487,  0.0266]], requires_grad=True)}\n",
      "[7, 29, 15, 0, 33]\n",
      "[22, 23, 25, 16, 27]\n",
      "0.0\n",
      "[7, 29, 15, 0, 33, 13, 4, 17, 22, 2]\n",
      "[22, 23, 25, 16, 27, 29, 9, 19, 26, 21]\n",
      "0.2\n",
      "[7, 29, 15, 0, 33, 13, 4, 17, 22, 2, 27, 5, 16, 26, 32]\n",
      "[22, 23, 25, 16, 27, 29, 9, 19, 26, 21, 8, 11, 28, 12, 5]\n",
      "0.4\n",
      "[7, 29, 15, 0, 33, 13, 4, 17, 22, 2, 27, 5, 16, 26, 32, 6, 19, 24, 34, 30]\n",
      "[22, 23, 25, 16, 27, 29, 9, 19, 26, 21, 8, 11, 28, 12, 5, 6, 1, 17, 18, 14]\n",
      "0.45\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)\n",
    "\n",
    "cv_path_1 = SAVE_DIR_MODEL_DATA+'model_assessment/gcn/weights/W_MainModel_3Fold_gender_data_gcn_run_0_CV_0_view_0_TEST.pickle'\n",
    "cv_path_2 = SAVE_DIR_MODEL_DATA+'model_assessment/gcn/weights/W_MainModel_3Fold_gender_data_gcn_run_0_CV_0_view_0_TEST_2.pickle'\n",
    "cv_path_3 = SAVE_DIR_MODEL_DATA+'model_assessment/gcn/weights/W_MainModel_3Fold_gender_data_gcn_run_0_CV_0_view_0_TEST_3.pickle'\n",
    "\n",
    "with open(cv_path_1,'rb') as f:\n",
    "    weights_1 = CPU_Unpickler(f).load()\n",
    "\n",
    "with open(cv_path_2,'rb') as f:\n",
    "    weights_2 = CPU_Unpickler(f).load()\n",
    "\n",
    "with open(cv_path_3,'rb') as f:\n",
    "    weights_2 = CPU_Unpickler(f).load()\n",
    "\n",
    "print(weights_1)\n",
    "print(weights_2)\n",
    "\n",
    "Ks = [5, 10, 15, 20]\n",
    "teacher_weights = weights_1[\"w\"].squeeze().detach().numpy()\n",
    "student_weight = weights_2[\"w\"].squeeze().detach().numpy()\n",
    "for k in Ks:\n",
    "    top_bio_i = top_biomarkers(teacher_weights, k)\n",
    "    top_bio_j = top_biomarkers(student_weight, k)\n",
    "    print(top_bio_i)\n",
    "    print(top_bio_j)\n",
    "    print(sim(top_bio_i, top_bio_j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 16.,  44.,  72.],\n",
      "        [100., 128., 156.],\n",
      "        [184., 212., 240.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a 3x3x4 tensor\n",
    "tensor = torch.tensor([\n",
    "    [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]],\n",
    "    [[13, 14, 15, 16], [17, 18, 19, 20], [21, 22, 23, 24]],\n",
    "    [[25, 26, 27, 28], [29, 30, 31, 32], [33, 34, 35, 36]]\n",
    "])\n",
    "\n",
    "# Define the coefficients for multiplication and addition\n",
    "coefficients = torch.tensor([0.5, 2.0, 1.5, 0.1])\n",
    "\n",
    "# Multiply and accumulate along the third axis\n",
    "result = tensor[:, :, 0]\n",
    "for i in range(1, tensor.shape[2]):\n",
    "    result = result * coefficients[i-1] + tensor[:, :, i]\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros([3,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# Create 4 individual 3x3 matrices\n",
    "matrix1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "matrix2 = torch.tensor([[10, 11, 12], [13, 14, 15], [16, 17, 18]])\n",
    "matrix3 = torch.tensor([[19, 20, 21], [22, 23, 24], [25, 26, 27]])\n",
    "matrix4 = torch.tensor([[28, 29, 30], [31, 32, 33], [34, 35, 36]])\n",
    "\n",
    "# Stack the matrices along the first dimension to create a (3x3) x 4 tensor\n",
    "tensor = torch.stack([matrix1, matrix2, matrix3, matrix4], dim=0)\n",
    "\n",
    "# Print the tensor\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(nodes1, nodes2):\n",
    "    if len(nodes1)==len(nodes2):\n",
    "        counter = 0\n",
    "        for i in nodes1:\n",
    "            for k in nodes2:\n",
    "                if i==k:\n",
    "                    counter+=1\n",
    "        return counter/len(nodes1)\n",
    "\n",
    "    else:\n",
    "        print('nodes vectors are not compatible')\n",
    "        \n",
    "def view_specific_rep(dataset, view, model, CV, run):\n",
    "\n",
    "    Ks = [5, 10, 15, 20]\n",
    "    rep = np.zeros([len(Ks), len(CV), len(CV)])\n",
    "\n",
    "    for k in range(rep.shape[0]):\n",
    "        for i in range(rep.shape[1]):\n",
    "            for j in range(rep.shape[2]):\n",
    "                weights_i = extract_weights(dataset, view, model, CV[i], run)\n",
    "                weights_j = extract_weights(dataset, view, model, CV[j], run)\n",
    "                top_bio_i = top_biomarkers(weights_i, Ks[k])\n",
    "                top_bio_j = top_biomarkers(weights_j, Ks[k])\n",
    "                rep[k,i,j] = sim(top_bio_i, top_bio_j)\n",
    "    \n",
    "    print(rep)\n",
    "    # Define the coefficients for multiplication and addition\n",
    "    coefficients = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "    # Multiply and accumulate along the third axis\n",
    "    rep_mean = np.zeros([3,3])\n",
    "    print(rep_mean)\n",
    "    for i in range(0, rep.shape[0]):\n",
    "        rep_mean = rep_mean * coefficients[i] + rep[i, :, :]\n",
    "    \n",
    "    print(rep_mean)\n",
    "    # Get the elements above the diagonal\n",
    "    elements_above_diagonal = np.where(np.triu(np.ones_like(rep_mean), k=1), rep_mean, np.nan)\n",
    "\n",
    "    # Drop the zeros and calculate the average\n",
    "    average = np.nanmean(elements_above_diagonal)\n",
    "    std = np.nanstd(elements_above_diagonal)\n",
    "    \n",
    "    return average, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.         0.2        0.        ]\n",
      "  [0.2        1.         0.2       ]\n",
      "  [0.         0.2        1.        ]]\n",
      "\n",
      " [[1.         0.8        0.2       ]\n",
      "  [0.8        1.         0.2       ]\n",
      "  [0.2        0.2        1.        ]]\n",
      "\n",
      " [[1.         0.73333333 0.4       ]\n",
      "  [0.73333333 1.         0.33333333]\n",
      "  [0.4        0.33333333 1.        ]]\n",
      "\n",
      " [[1.         0.75       0.7       ]\n",
      "  [0.75       1.         0.6       ]\n",
      "  [0.7        0.6        1.        ]]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1.328125   0.98645833 0.8125    ]\n",
      " [0.98645833 1.328125   0.69895833]\n",
      " [0.8125     0.69895833 1.328125  ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8326388888888889, 0.11823209838916914)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_specific_rep(dataset=\"gender_data\", view=0, model=\"gcn\", CV= [\"3Fold\", \"5Fold\", \"10Fold\"], run=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_specific_rep(dataset, view, model, CV, run):\n",
    "\n",
    "    Ks = [5, 10, 15, 20]\n",
    "    rep = np.zeros([len(CV), len(CV), len(Ks)])\n",
    "\n",
    "    for i in range(rep.shape[0]):\n",
    "        for j in range(rep.shape[1]):\n",
    "            weights_i = extract_weights(dataset, view, model, CV[i], run)\n",
    "            weights_j = extract_weights(dataset, view, model, CV[j], run)\n",
    "            \n",
    "            for k in range(rep.shape[2]):\n",
    "                top_bio_i = top_biomarkers(weights_i, Ks[k])\n",
    "                top_bio_j = top_biomarkers(weights_j, Ks[k])\n",
    "                rep[i,j,k] = sim(top_bio_i, top_bio_j)\n",
    "                \n",
    "    rep_mean = np.mean(rep, axis=2)\n",
    "    # Get the elements above the diagonal\n",
    "    elements_above_diagonal = np.where(np.triu(np.ones_like(rep_mean), k=1), rep_mean, np.nan)\n",
    "\n",
    "    # Drop the zeros and calculate the average\n",
    "    average = np.nanmean(elements_above_diagonal)\n",
    "    std = np.nanstd(elements_above_diagonal)\n",
    "    \n",
    "    return average, std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.42638888888888893, 0.1375350684797459)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_specific_rep(dataset=\"gender_data\", view=0, model=\"gcn\", CV= [\"3Fold\", \"5Fold\", \"10Fold\"], run=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loaders import *\n",
    "\n",
    "G_list = load_data(\"gender_data\", 0, NormalizeInputGraphs=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(G_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from analysis import *\n",
    "from getters import * \n",
    "from plotters import * \n",
    "\n",
    "views=[0]\n",
    "models=[\"gcn_student_ensamble_3\"]\n",
    "CV=[\"3Fold\", \"5Fold\", \"10Fold\"]\n",
    "run=0\n",
    "dataset = \"gender_data\"\n",
    "gcn_student_ensamble_args = {\n",
    "    \"num_epochs\":50, \n",
    "    \"lr\": 0.0001, # 0.0001 when training without teacher\n",
    "    \"weight_decay\":5e-4, \n",
    "    \"hidden_dim\":64,\n",
    "    \"dropout\":0,\n",
    "    \"threshold\":\"median\", # Threshold the graph adjacency matrix. Possible values: no_threshold, median, mean\n",
    "    \"model_name\":\"gcn_student_ensamble_3\",\n",
    "    \"evaluation_method\": \"model_assessment\", # model selection or model assessment\n",
    "    \"alpha\": 1, # ensamble ce loss\n",
    "    \"beta\": 2,  # ensamble kd loss\n",
    "    \"gamma\": 2, # sum of student ce loss\n",
    "    \"lambda\":1, # disentanglement loss\n",
    "    \"T\": 3, #Temperature parameter for soft logit target \n",
    "    \"n_students\":3 # TOTAL number of students in ensamble \n",
    "}\n",
    "\n",
    "view_data_mean, _ = view_reproducibility_analysis(dataset, models, CV, views, run, student=0, model_args=gcn_student_ensamble_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_data_mean_1, _ = view_reproducibility_analysis(dataset, models, CV, views, run, student=0, model_args=gcn_student_ensamble_args)\n",
    "view_data_mean_2, _ = view_reproducibility_analysis(dataset, models, CV, views, run, student=1, model_args=gcn_student_ensamble_args)\n",
    "view_data_mean_3, _ = view_reproducibility_analysis(dataset, models, CV, views, run, student=2, model_args=gcn_student_ensamble_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.88888889, 0.88888889]]),\n",
       " array([[0.93333333, 0.93333333]]),\n",
       " array([[0.98333333, 0.98333333]]))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_data_mean_1, view_data_mean_2, view_data_mean_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcn_student_ensamble_args = {\n",
    "    \"num_epochs\":50, \n",
    "    \"lr\": 0.0001, # 0.0001 when training without teacher\n",
    "    \"weight_decay\":5e-4, \n",
    "    \"hidden_dim\":64,\n",
    "    \"dropout\":0,\n",
    "    \"threshold\":\"median\", # Threshold the graph adjacency matrix. Possible values: no_threshold, median, mean\n",
    "    \"model_name\":\"gcn_student_ensamble_3\",\n",
    "    \"evaluation_method\": \"model_assessment\", # model selection or model assessment\n",
    "    \"alpha\": 1, # ensamble ce loss\n",
    "    \"beta\": 2,  # ensamble kd loss\n",
    "    \"gamma\": 2, # sum of student ce loss\n",
    "    \"lambda\":1, # disentanglement loss\n",
    "    \"T\": 3, #Temperature parameter for soft logit target \n",
    "    \"n_students\":3 # TOTAL number of students in ensamble \n",
    "}\n",
    "\n",
    "x = get_labels_and_preds(dataset, \"gcn_student_ensamble_3\",\"model_assessment\", \"5Fold\",  4, 0, 0, \"val\", student=1, model_args=gcn_student_ensamble_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5501768346595933"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student = []\n",
    "acc_mean = []\n",
    "for i in range(3):\n",
    "    for i in range(3):\n",
    "        x = get_labels_and_preds(dataset, \"gcn_student_ensamble_3\",\"model_assessment\", \"3Fold\",  i, 0, 0, \"val\", student=2, model_args=gcn_student_ensamble_args)\n",
    "        result = {\n",
    "        'prec': metrics.precision_score(x['labels'],  x['preds']),\n",
    "        'recall': metrics.recall_score(x['labels'],  x['preds']),\n",
    "        'acc': metrics.accuracy_score(x['labels'],  x['preds']),\n",
    "        'F1': metrics.f1_score(x['labels'],  x['preds'])\n",
    "        }   \n",
    "        acc_mean.append(result['acc'])\n",
    "    student.append(np.mean(acc_mean))\n",
    "np.mean(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5183098591549296"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student = []\n",
    "acc_mean = []\n",
    "for i in range(5):\n",
    "    for i in range(5):\n",
    "        x = get_labels_and_preds(dataset, \"gcn_student_ensamble_3\",\"model_assessment\", \"5Fold\",  i, 0, 0, \"val\", student=2, model_args=gcn_student_ensamble_args)\n",
    "        result = {\n",
    "        'prec': metrics.precision_score(x['labels'],  x['preds']),\n",
    "        'recall': metrics.recall_score(x['labels'],  x['preds']),\n",
    "        'acc': metrics.accuracy_score(x['labels'],  x['preds']),\n",
    "        'F1': metrics.f1_score(x['labels'],  x['preds'])\n",
    "        }   \n",
    "        acc_mean.append(result['acc'])\n",
    "    student.append(np.mean(acc_mean))\n",
    "np.mean(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.541501976284585"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student = []\n",
    "acc_mean = []\n",
    "for i in range(10):\n",
    "    for i in range(10):\n",
    "        x = get_labels_and_preds(dataset, \"gcn_student_ensamble_3\",\"model_assessment\", \"10Fold\",  i, 0, 0, \"val\", student=2, model_args=gcn_student_ensamble_args)\n",
    "        result = {\n",
    "        'prec': metrics.precision_score(x['labels'],  x['preds']),\n",
    "        'recall': metrics.recall_score(x['labels'],  x['preds']),\n",
    "        'acc': metrics.accuracy_score(x['labels'],  x['preds']),\n",
    "        'F1': metrics.f1_score(x['labels'],  x['preds'])\n",
    "        }   \n",
    "        acc_mean.append(result['acc'])\n",
    "    student.append(np.mean(acc_mean))\n",
    "np.mean(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-test",
   "language": "python",
   "name": "env-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
